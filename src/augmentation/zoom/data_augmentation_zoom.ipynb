{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif\n",
    "Ce notebook vise à explorer les techniques d'augmentation de données d'images et à construire un modèle de classification pour identifier les pneumonies à partir d'images de rayons X. Les étapes clés incluent l'augmentation des données, l'entraînement d'un modèle CNN et l'évaluation des performances du modèle.\n",
    "\n",
    "## Étapes de Démarche\n",
    "\n",
    "1. **Vérification de la Disponibilité du GPU**\n",
    "2. **Chargement et Préparation des Données**\n",
    "   - Chargement, redimensionnement, conversion en niveaux de gris, normalisation et restructuration des images.\n",
    "3. **Visualisation des Données**\n",
    "4. **Augmentation des Données**\n",
    "5. **Définition et Entraînement du Modèle CNN**\n",
    "6. **Évaluation du Modèle**\n",
    "7. **Visualisation des Performances**\n",
    "   - Matrice de confusion, rapport de classification et courbe ROC.\n",
    "8. **Heatmaps des Activations**\n",
    "\n",
    "## Interprétation et Résultats\n",
    "- **Courbes d'Apprentissage** : convergence du modèle et relation entre la perte et l'exactitude.\n",
    "- **Matrice de Confusion** : répartition des erreurs de classification.\n",
    "- **Rapport de Classification** : mesures détaillées comme la précision, le rappel et le score F1.\n",
    "- **Courbe ROC** : capacité du modèle à distinguer les classes à différents seuils.\n",
    "- **Heatmaps des Activations** : caractéristiques extraites par les couches du modèle.ion des données d'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_curve, auc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifie si des GPUs sont disponibles parce que si ils le sont alors ça accélère les calculs lors de l'entraînement du modèle, donc ça réduit le temps d'entaînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de GPUs disponibles :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de GPUs disponibles : \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 150 #150x150 pixels\n",
    "data_dir1 = '../../../chest_xray/train/PNEUMONIA'\n",
    "data_dir2 = '../../../chest_xray/train/NORMAL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger et prétraiter les images à partir des 2 répertoires spécifiés. Cette fonction prend en entrée deux chemins de répertoire (data_dir1 et data_dir2) et retourne un tableau contenant les images redimensionnées et leurs étiquettes respectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir1, data_dir2):\n",
    "    data = []\n",
    "    labels = ['PNEUMONIA', 'NORMAL']\n",
    "    for dir in [data_dir1, data_dir2]:\n",
    "        path = os.path.join(dir)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Le répertoire {path} n'existe pas.\")\n",
    "            continue\n",
    "        label = os.path.basename(dir)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                if img_arr is None:\n",
    "                    print(f\"Échec de lecture de {img}. Ignoré.\")\n",
    "                    continue\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data, dtype=object)\n",
    "\n",
    "train_data = load_data(data_dir1, data_dir2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation du nombre d'images par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count = [0, 0]\n",
    "for item in train_data:\n",
    "    labels_count[item[1]] += 1\n",
    "\n",
    "plt.bar(['PNEUMONIA', 'NORMAL'], labels_count)\n",
    "plt.title('Nombre d\\'images par classe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendre en entrée les données (features et labels) et les sépare en deux tableaux distincts : un pour les features (images) et un autre pour les labels (étiquettes de classe).\n",
    "\n",
    "- **Normaliser** : \r\n",
    "  - Chaque pixel d'une image a une valeur entre 0 et 255.\r\n",
    "  - Normaliser signifie diviser ces valeurs par 255 pour qu'elles soient entre 0 et 1.\r\n",
    " Caela facilite l'entraînement du modèparce quecar les valeurs sont plus petites et plus uniformes.\r\n",
    "\r\n",
    "- **Reshaper** :\r\n",
    "  - Les images sont des tableaux de nombres (valeurs des pixels).\r\n",
    "  - Reveut direignifie réorganiser ces tableaux pour qu'ils aient une forme spécifique.\r\n",
    "  - On veut que chaque image ait la forme (nombre d'images, 150, 150, 1).\r\n",
    "  - Cela indique qu'on a un certain nombre d'images, que chaque image a une taille de 150x150 pixels, et qu'elle est en niveaux de gris (1 canal de couleur).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#normaliser les données en divisant par 255\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m separate_features_labels(train_data)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Normaliser les données\u001b[39;00m\n\u001b[0;32m     13\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "def separate_features_labels(data):\n",
    "    features, labels = [], []\n",
    "    # séparation des features et des labels\n",
    "    for feature, label in data:\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "#normaliser les données en divisant par 255\n",
    "x_train, y_train = separate_features_labels(train_data)\n",
    "\n",
    "# Normaliser les données\n",
    "x_train = x_train / 255.0\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
