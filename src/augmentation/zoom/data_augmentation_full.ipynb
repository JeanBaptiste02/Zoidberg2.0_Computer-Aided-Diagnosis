{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Define constants\n",
    "img_size = 150\n",
    "data_dir1 = '../../../chest_xray/train/PNEUMONIA'\n",
    "data_dir2 = '../../../chest_xray/train/NORMAL'\n",
    "\n",
    "# Function to load data\n",
    "def load_data(data_dir1, data_dir2):\n",
    "    data = []\n",
    "    labels = ['PNEUMONIA', 'NORMAL']\n",
    "    for dir in [data_dir1, data_dir2]:\n",
    "        path = os.path.join(dir)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Directory {path} does not exist.\")\n",
    "            continue\n",
    "        label = os.path.basename(dir)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                if img_arr is None:\n",
    "                    print(f\"Failed to read {img}. Skipping.\")\n",
    "                    continue\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data, dtype=object)\n",
    "\n",
    "train_data = load_data(data_dir1, data_dir2)\n",
    "\n",
    "# Visualize the number of images per class\n",
    "labels_count = [0, 0]\n",
    "for item in train_data:\n",
    "    labels_count[item[1]] += 1\n",
    "\n",
    "plt.bar(['PNEUMONIA', 'NORMAL'], labels_count)\n",
    "plt.title('Number of images per class')\n",
    "plt.show()\n",
    "\n",
    "# Separate features and labels\n",
    "def separate_features_labels(data):\n",
    "    features, labels = [], []\n",
    "    for feature, label in data:\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "x_train, y_train = separate_features_labels(train_data)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "# Ensure data is not empty\n",
    "if x_train.size == 0 or y_train.size == 0:\n",
    "    print(\"Training data is empty. Please check the data loading process.\")\n",
    "else:\n",
    "    # Full data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Display some augmented images\n",
    "    def display_augmented_images(datagen, x_train, y_train):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=5):\n",
    "            for i in range(5):\n",
    "                plt.subplot(330 + 1 + i)\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.imshow(x_batch[i].reshape(img_size, img_size), cmap='gray')\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "    display_augmented_images(datagen, x_train, y_train)\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks to adjust learning rate and stop training if stagnation occurs\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "    # Train the model with augmented data\n",
    "    history = model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=20, callbacks=[reduce_lr, early_stop])\n",
    "\n",
    "    # Display performance curves\n",
    "    def plot_learning_curves(history):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Display learning curves\n",
    "    plot_learning_curves(history)\n",
    "\n",
    "    # Model evaluation\n",
    "    scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "    print(f\"Model accuracy: {scores[1]*100:.2f}%\")\n",
    "    print(f\"Model loss: {scores[0]:.4f}\")\n",
    "\n",
    "    # Display some predictions\n",
    "    def display_predictions(model, x_train, y_train):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        predictions = (model.predict(x_train) > 0.5).astype(\"int32\")\n",
    "        for i in range(9):\n",
    "            plt.subplot(330 + 1 + i)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.imshow(x_train[i].reshape(img_size, img_size), cmap='gray')\n",
    "            plt.title(f\"Pred: {predictions[i][0]}, True: {y_train[i]}\")\n",
    "        plt.show()\n",
    "\n",
    "    display_predictions(model, x_train, y_train)\n",
    "\n",
    "    print(\"Full data augmentation and model evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
