{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce7b311-7df2-47b7-bfaf-c819f9d294a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63c7ecf-2528-4c79-b835-64a3244cec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification GPU...\n",
      "Aucun GPU détecté, l'entraînement se fera sur le CPU.\n"
     ]
    }
   ],
   "source": [
    "print(\"Vérification GPU...\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU détecté.\")\n",
    "else:\n",
    "    print(\"Aucun GPU détecté, l'entraînement se fera sur le CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a71fd5-9033-4160-ae66-7a652031130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "n_folds = 10\n",
    "filter_numbers = [128, 256, 512, 1024]\n",
    "data_dir1 = '../../../chest_xray/train/PNEUMONIA'\n",
    "data_dir2 = '../../../chest_xray/train/NORMAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610023bd-8406-477f-92be-645ae1ff00df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Chargement des données terminé.\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir1, data_dir2, limit=100):\n",
    "    print(\"Chargement des données...\")\n",
    "    data = []\n",
    "    labels = ['PNEUMONIA', 'NORMAL']\n",
    "    for dir in [data_dir1, data_dir2]:\n",
    "        path = os.path.join(dir)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Le répertoire {path} n'existe pas\")\n",
    "            continue\n",
    "        label = os.path.basename(dir)\n",
    "        class_num = labels.index(label)\n",
    "        for i, img in enumerate(os.listdir(path)):\n",
    "            if i >= limit:\n",
    "                break\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                if img_arr is None:\n",
    "                    print(f\"Échec de la lecture de {img}. Passage au suivant.\")\n",
    "                    continue\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    print(\"Chargement des données terminé.\")\n",
    "    return np.array(data, dtype=object)\n",
    "\n",
    "train_data = load_data(data_dir1, data_dir2, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967d6308-b87e-4d7f-938d-f08898f218b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des données...\n",
      "Traitement de l'image 1/200\n",
      "Traitement de l'image 2/200\n",
      "Traitement de l'image 3/200\n",
      "Traitement de l'image 4/200\n",
      "Traitement de l'image 5/200\n",
      "Traitement de l'image 6/200\n",
      "Traitement de l'image 7/200\n",
      "Traitement de l'image 8/200\n",
      "Traitement de l'image 9/200\n",
      "Traitement de l'image 10/200\n",
      "Traitement de l'image 11/200\n",
      "Traitement de l'image 12/200\n",
      "Traitement de l'image 13/200\n",
      "Traitement de l'image 14/200\n",
      "Traitement de l'image 15/200\n",
      "Traitement de l'image 16/200\n",
      "Traitement de l'image 17/200\n",
      "Traitement de l'image 18/200\n",
      "Traitement de l'image 19/200\n",
      "Traitement de l'image 20/200\n",
      "Traitement de l'image 21/200\n",
      "Traitement de l'image 22/200\n",
      "Traitement de l'image 23/200\n",
      "Traitement de l'image 24/200\n",
      "Traitement de l'image 25/200\n",
      "Traitement de l'image 26/200\n",
      "Traitement de l'image 27/200\n",
      "Traitement de l'image 28/200\n",
      "Traitement de l'image 29/200\n",
      "Traitement de l'image 30/200\n",
      "Traitement de l'image 31/200\n",
      "Traitement de l'image 32/200\n",
      "Traitement de l'image 33/200\n",
      "Traitement de l'image 34/200\n",
      "Traitement de l'image 35/200\n",
      "Traitement de l'image 36/200\n",
      "Traitement de l'image 37/200\n",
      "Traitement de l'image 38/200\n",
      "Traitement de l'image 39/200\n",
      "Traitement de l'image 40/200\n",
      "Traitement de l'image 41/200\n",
      "Traitement de l'image 42/200\n",
      "Traitement de l'image 43/200\n",
      "Traitement de l'image 44/200\n",
      "Traitement de l'image 45/200\n",
      "Traitement de l'image 46/200\n",
      "Traitement de l'image 47/200\n",
      "Traitement de l'image 48/200\n",
      "Traitement de l'image 49/200\n",
      "Traitement de l'image 50/200\n",
      "Traitement de l'image 51/200\n",
      "Traitement de l'image 52/200\n",
      "Traitement de l'image 53/200\n",
      "Traitement de l'image 54/200\n",
      "Traitement de l'image 55/200\n",
      "Traitement de l'image 56/200\n",
      "Traitement de l'image 57/200\n",
      "Traitement de l'image 58/200\n",
      "Traitement de l'image 59/200\n",
      "Traitement de l'image 60/200\n",
      "Traitement de l'image 61/200\n",
      "Traitement de l'image 62/200\n",
      "Traitement de l'image 63/200\n",
      "Traitement de l'image 64/200\n",
      "Traitement de l'image 65/200\n",
      "Traitement de l'image 66/200\n",
      "Traitement de l'image 67/200\n",
      "Traitement de l'image 68/200\n",
      "Traitement de l'image 69/200\n",
      "Traitement de l'image 70/200\n",
      "Traitement de l'image 71/200\n",
      "Traitement de l'image 72/200\n",
      "Traitement de l'image 73/200\n",
      "Traitement de l'image 74/200\n",
      "Traitement de l'image 75/200\n",
      "Traitement de l'image 76/200\n",
      "Traitement de l'image 77/200\n",
      "Traitement de l'image 78/200\n",
      "Traitement de l'image 79/200\n",
      "Traitement de l'image 80/200\n",
      "Traitement de l'image 81/200\n",
      "Traitement de l'image 82/200\n",
      "Traitement de l'image 83/200\n",
      "Traitement de l'image 84/200\n",
      "Traitement de l'image 85/200\n",
      "Traitement de l'image 86/200\n",
      "Traitement de l'image 87/200\n",
      "Traitement de l'image 88/200\n",
      "Traitement de l'image 89/200\n",
      "Traitement de l'image 90/200\n",
      "Traitement de l'image 91/200\n",
      "Traitement de l'image 92/200\n",
      "Traitement de l'image 93/200\n",
      "Traitement de l'image 94/200\n",
      "Traitement de l'image 95/200\n",
      "Traitement de l'image 96/200\n",
      "Traitement de l'image 97/200\n",
      "Traitement de l'image 98/200\n",
      "Traitement de l'image 99/200\n",
      "Traitement de l'image 100/200\n",
      "Traitement de l'image 101/200\n",
      "Traitement de l'image 102/200\n",
      "Traitement de l'image 103/200\n",
      "Traitement de l'image 104/200\n",
      "Traitement de l'image 105/200\n",
      "Traitement de l'image 106/200\n",
      "Traitement de l'image 107/200\n",
      "Traitement de l'image 108/200\n",
      "Traitement de l'image 109/200\n",
      "Traitement de l'image 110/200\n",
      "Traitement de l'image 111/200\n",
      "Traitement de l'image 112/200\n",
      "Traitement de l'image 113/200\n",
      "Traitement de l'image 114/200\n",
      "Traitement de l'image 115/200\n",
      "Traitement de l'image 116/200\n",
      "Traitement de l'image 117/200\n",
      "Traitement de l'image 118/200\n",
      "Traitement de l'image 119/200\n",
      "Traitement de l'image 120/200\n",
      "Traitement de l'image 121/200\n",
      "Traitement de l'image 122/200\n",
      "Traitement de l'image 123/200\n",
      "Traitement de l'image 124/200\n",
      "Traitement de l'image 125/200\n",
      "Traitement de l'image 126/200\n",
      "Traitement de l'image 127/200\n",
      "Traitement de l'image 128/200\n",
      "Traitement de l'image 129/200\n",
      "Traitement de l'image 130/200\n",
      "Traitement de l'image 131/200\n",
      "Traitement de l'image 132/200\n",
      "Traitement de l'image 133/200\n",
      "Traitement de l'image 134/200\n",
      "Traitement de l'image 135/200\n",
      "Traitement de l'image 136/200\n",
      "Traitement de l'image 137/200\n",
      "Traitement de l'image 138/200\n",
      "Traitement de l'image 139/200\n",
      "Traitement de l'image 140/200\n",
      "Traitement de l'image 141/200\n",
      "Traitement de l'image 142/200\n",
      "Traitement de l'image 143/200\n",
      "Traitement de l'image 144/200\n",
      "Traitement de l'image 145/200\n",
      "Traitement de l'image 146/200\n",
      "Traitement de l'image 147/200\n",
      "Traitement de l'image 148/200\n",
      "Traitement de l'image 149/200\n",
      "Traitement de l'image 150/200\n",
      "Traitement de l'image 151/200\n",
      "Traitement de l'image 152/200\n",
      "Traitement de l'image 153/200\n",
      "Traitement de l'image 154/200\n",
      "Traitement de l'image 155/200\n",
      "Traitement de l'image 156/200\n",
      "Traitement de l'image 157/200\n",
      "Traitement de l'image 158/200\n",
      "Traitement de l'image 159/200\n",
      "Traitement de l'image 160/200\n",
      "Traitement de l'image 161/200\n",
      "Traitement de l'image 162/200\n",
      "Traitement de l'image 163/200\n",
      "Traitement de l'image 164/200\n",
      "Traitement de l'image 165/200\n",
      "Traitement de l'image 166/200\n",
      "Traitement de l'image 167/200\n",
      "Traitement de l'image 168/200\n",
      "Traitement de l'image 169/200\n",
      "Traitement de l'image 170/200\n",
      "Traitement de l'image 171/200\n",
      "Traitement de l'image 172/200\n",
      "Traitement de l'image 173/200\n",
      "Traitement de l'image 174/200\n",
      "Traitement de l'image 175/200\n",
      "Traitement de l'image 176/200\n",
      "Traitement de l'image 177/200\n",
      "Traitement de l'image 178/200\n",
      "Traitement de l'image 179/200\n",
      "Traitement de l'image 180/200\n",
      "Traitement de l'image 181/200\n",
      "Traitement de l'image 182/200\n",
      "Traitement de l'image 183/200\n",
      "Traitement de l'image 184/200\n",
      "Traitement de l'image 185/200\n",
      "Traitement de l'image 186/200\n",
      "Traitement de l'image 187/200\n",
      "Traitement de l'image 188/200\n",
      "Traitement de l'image 189/200\n",
      "Traitement de l'image 190/200\n",
      "Traitement de l'image 191/200\n",
      "Traitement de l'image 192/200\n",
      "Traitement de l'image 193/200\n",
      "Traitement de l'image 194/200\n",
      "Traitement de l'image 195/200\n",
      "Traitement de l'image 196/200\n",
      "Traitement de l'image 197/200\n",
      "Traitement de l'image 198/200\n",
      "Traitement de l'image 199/200\n",
      "Traitement de l'image 200/200\n"
     ]
    }
   ],
   "source": [
    "# Prétraitement des images\n",
    "def preprocess_image(image):\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "    image = tf.image.resize(image, [img_size, img_size])\n",
    "    image = image / 255.0  # Normalisation\n",
    "    return image\n",
    "\n",
    "# Prétraitement des données\n",
    "def preprocess_data(data):\n",
    "    print(\"Prétraitement des données...\")\n",
    "    processed_data = []\n",
    "    for idx, (img, label) in enumerate(data):\n",
    "        print(f\"Traitement de l'image {idx+1}/{len(data)}\")\n",
    "        img = preprocess_image(img)\n",
    "        processed_data.append([img, label])\n",
    "    return np.array(processed_data, dtype=object)\n",
    "\n",
    "train_data = preprocess_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b60932-af3a-441c-9b82-22558ef6f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_features_labels(data):\n",
    "    images = np.array([item[0] for item in data])\n",
    "    labels = np.array([item[1] for item in data])\n",
    "    return images, labels\n",
    "\n",
    "x_train, y_train = separate_features_labels(train_data)\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "x_train = np.concatenate([x_train, x_train, x_train], axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b8d41-c79f-4fdb-a739-fd893c5beb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation avec 128 filtres\n",
      "Traitement du pli 1/10\n",
      "Définition du modèle avec 128 filtres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikne\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle défini.\n",
      "Modèle compilé\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikne\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6s/step - accuracy: 0.4446 - loss: 0.8337 - val_accuracy: 0.5000 - val_loss: 0.6919 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.4958 - loss: 0.6963 - val_accuracy: 0.5000 - val_loss: 0.6899 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5s/step - accuracy: 0.4423 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6868 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6s/step - accuracy: 0.5281 - loss: 0.6884 - val_accuracy: 0.5000 - val_loss: 0.6816 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - accuracy: 0.6357 - loss: 0.6737 - val_accuracy: 0.5000 - val_loss: 0.6558 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - accuracy: 0.5964 - loss: 0.6500 - val_accuracy: 0.5000 - val_loss: 0.6781 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6s/step - accuracy: 0.5686 - loss: 0.6727 - val_accuracy: 0.5000 - val_loss: 0.6723 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5s/step - accuracy: 0.5262 - loss: 0.6672 - val_accuracy: 0.7000 - val_loss: 0.6228 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5s/step - accuracy: 0.7193 - loss: 0.6195 - val_accuracy: 0.6500 - val_loss: 0.5061 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - accuracy: 0.6947 - loss: 0.5971 - val_accuracy: 0.7000 - val_loss: 0.4520 - learning_rate: 0.0010\n",
      "Précision de validation pour le pli 1: 70.00%\n",
      "Traitement du pli 1/10\n",
      "Définition du modèle avec 128 filtres...\n",
      "Modèle défini.\n",
      "Modèle compilé\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6s/step - accuracy: 0.4962 - loss: 1.7628 - val_accuracy: 0.4500 - val_loss: 0.6973 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5s/step - accuracy: 0.5150 - loss: 0.6946 - val_accuracy: 0.4500 - val_loss: 0.6861 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6s/step - accuracy: 0.5056 - loss: 0.7099 - val_accuracy: 0.5500 - val_loss: 0.6909 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6s/step - accuracy: 0.5485 - loss: 0.6902 - val_accuracy: 0.4500 - val_loss: 0.6974 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6s/step - accuracy: 0.4926 - loss: 0.6935 - val_accuracy: 0.4500 - val_loss: 0.6947 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5s/step - accuracy: 0.5113 - loss: 0.6932 - val_accuracy: 0.4500 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5s/step - accuracy: 0.5191 - loss: 0.6885 - val_accuracy: 0.4500 - val_loss: 0.6908 - learning_rate: 5.0000e-04\n",
      "Précision de validation pour le pli 1: 45.00%\n",
      "Traitement du pli 1/10\n",
      "Définition du modèle avec 128 filtres...\n",
      "Modèle défini.\n",
      "Modèle compilé\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6s/step - accuracy: 0.4497 - loss: 0.8265 - val_accuracy: 0.5000 - val_loss: 0.7047 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - accuracy: 0.5432 - loss: 0.6939 - val_accuracy: 0.5000 - val_loss: 0.6916 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - accuracy: 0.5392 - loss: 0.6943 - val_accuracy: 0.5000 - val_loss: 0.6713 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6s/step - accuracy: 0.5760 - loss: 0.6880 - val_accuracy: 0.9000 - val_loss: 0.6641 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6s/step - accuracy: 0.5582 - loss: 0.6806 - val_accuracy: 0.7000 - val_loss: 0.6403 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.6694 - loss: 0.6416 - val_accuracy: 0.5000 - val_loss: 0.7295 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6s/step - accuracy: 0.5028 - loss: 0.7326 - val_accuracy: 0.8000 - val_loss: 0.6038 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6s/step - accuracy: 0.7442 - loss: 0.5747 - val_accuracy: 0.8000 - val_loss: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5s/step - accuracy: 0.7926 - loss: 0.4753 - val_accuracy: 0.9500 - val_loss: 0.2916 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5s/step - accuracy: 0.8612 - loss: 0.3672 - val_accuracy: 0.9000 - val_loss: 0.2940 - learning_rate: 0.0010\n",
      "Précision de validation pour le pli 1: 95.00%\n",
      "Traitement du pli 1/10\n",
      "Définition du modèle avec 128 filtres...\n",
      "Modèle défini.\n",
      "Modèle compilé\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5s/step - accuracy: 0.6328 - loss: 2.1953 - val_accuracy: 0.5500 - val_loss: 0.7452 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.3939 - loss: 0.7940 - val_accuracy: 0.4500 - val_loss: 0.6953 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5s/step - accuracy: 0.4775 - loss: 0.6932 - val_accuracy: 0.5500 - val_loss: 0.6903 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5s/step - accuracy: 0.4799 - loss: 0.6925 - val_accuracy: 0.5500 - val_loss: 0.6908 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5s/step - accuracy: 0.5535 - loss: 0.6921 - val_accuracy: 0.5500 - val_loss: 0.6852 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.5416 - loss: 0.6912 - val_accuracy: 0.5500 - val_loss: 0.6699 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5s/step - accuracy: 0.5708 - loss: 0.6741 - val_accuracy: 0.6000 - val_loss: 0.6704 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.6534 - loss: 0.6806 - val_accuracy: 0.6000 - val_loss: 0.6730 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.6950 - loss: 0.6604 - val_accuracy: 0.5500 - val_loss: 0.6307 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5s/step - accuracy: 0.7652 - loss: 0.5636 - val_accuracy: 0.6500 - val_loss: 0.6196 - learning_rate: 0.0010\n",
      "Précision de validation pour le pli 1: 65.00%\n",
      "Traitement du pli 1/10\n",
      "Définition du modèle avec 128 filtres...\n",
      "Modèle défini.\n",
      "Modèle compilé\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5s/step - accuracy: 0.4591 - loss: 1.9233 - val_accuracy: 0.5500 - val_loss: 0.6920 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.5668 - loss: 0.7082 - val_accuracy: 0.4500 - val_loss: 0.7009 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5s/step - accuracy: 0.4827 - loss: 0.6979 - val_accuracy: 0.6000 - val_loss: 0.6895 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5s/step - accuracy: 0.5250 - loss: 0.6904 - val_accuracy: 0.4500 - val_loss: 0.6939 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7s/step - accuracy: 0.5776 - loss: 0.6881 - val_accuracy: 0.4500 - val_loss: 0.6901 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.5388 - loss: 0.6888 - val_accuracy: 0.4500 - val_loss: 0.6833 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5s/step - accuracy: 0.5642 - loss: 0.6800 - val_accuracy: 0.4500 - val_loss: 0.6581 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.5952 - loss: 0.6407 - val_accuracy: 0.8500 - val_loss: 0.5411 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.5601 - loss: 0.6975 - val_accuracy: 0.7500 - val_loss: 0.5904 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5s/step - accuracy: 0.5969 - loss: 0.6460 - val_accuracy: 0.8000 - val_loss: 0.5452 - learning_rate: 0.0010\n",
      "Précision de validation pour le pli 1: 85.00%\n",
      "Traitement du pli 1/10\n",
      "Définition du modèle avec 128 filtres...\n",
      "Modèle défini.\n",
      "Modèle compilé\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step - accuracy: 0.5190 - loss: 1.0840 - val_accuracy: 0.5500 - val_loss: 0.6861 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5295 - loss: 0.6960"
     ]
    }
   ],
   "source": [
    "def create_model(n_filters):\n",
    "    print(f\"Définition du modèle avec {n_filters} filtres...\")\n",
    "    model = Sequential([\n",
    "        Conv2D(n_filters, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(n_filters*2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(n_filters*4, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(n_filters*8, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    print(\"Modèle défini.\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    print(\"Modèle compilé\")\n",
    "    return model\n",
    "\n",
    "# Validation croisée K-Fold\n",
    "for n_filters in filter_numbers:\n",
    "    print(f\"Évaluation avec {n_filters} filtres\")\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    fold = 1\n",
    "    fold_accuracies = []\n",
    "    training_times = []\n",
    "\n",
    "    for train_index, val_index in kf.split(x_train):\n",
    "        x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        print(f\"Traitement du pli {fold}/{n_folds}\")\n",
    "        datagen = ImageDataGenerator(zoom_range=0.1, shear_range=0.1)\n",
    "        datagen.fit(x_train_fold)\n",
    "        \n",
    "        model = create_model(n_filters)\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        history = model.fit(datagen.flow(x_train_fold, y_train_fold, batch_size=batch_size),\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_val_fold, y_val_fold),\n",
    "                            callbacks=[reduce_lr, early_stop])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        training_time = end_time - start_time\n",
    "        training_times.append(training_time)\n",
    "        \n",
    "        # Évaluation du pli\n",
    "        scores = model.evaluate(x_val_fold, y_val_fold, verbose=0)\n",
    "        print(f\"Précision de validation pour le pli {fold}: {scores[1]*100:.2f}%\")\n",
    "        fold_accuracies.append(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1228a4-3e64-40a6-a628-2b8592061a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label='Perte d\\'entraînement')\n",
    "        plt.plot(history.history['val_loss'], label='Perte de validation')\n",
    "        plt.xlabel('Époques')\n",
    "        plt.ylabel('Perte')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Précision d\\'entraînement')\n",
    "        plt.plot(history.history['val_accuracy'], label='Précision de validation')\n",
    "        plt.xlabel('Époques')\n",
    "        plt.ylabel('Précision')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d633049-425a-40e5-98c3-5ed63b23cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_de_confusion():\n",
    "     y_pred = (model.predict(x_val_fold) > 0.5).astype(\"int32\")\n",
    "    cm = confusion_matrix(y_val_fold, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['PNEUMONIA', 'NORMAL'], yticklabels=['PNEUMONIA', 'NORMAL'])\n",
    "    plt.ylabel('Réel')\n",
    "    plt.xlabel('Prévu')\n",
    "    plt.title(f'Matrice de confusion pour le pli {fold}')\n",
    "    plt.show()\n",
    "\n",
    "matrice_de_confusion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
