{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760ed437-cd39-49e4-ab57-f4bd195d6eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikne\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 658ms/step - AUC: 0.9686 - accuracy: 0.9249 - loss: 0.2027\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 389ms/step - AUC: 0.9757 - accuracy: 0.9258 - loss: 0.1958\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 353ms/step - AUC: 0.9660 - accuracy: 0.9040 - loss: 0.2191\n",
      "Layers: 2, Accuracy: 0.9259, AUC: 0.9751\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 420ms/step - AUC: 0.9869 - accuracy: 0.9426 - loss: 0.1367\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 421ms/step - AUC: 0.9678 - accuracy: 0.9047 - loss: 0.2220\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 437ms/step - AUC: 0.9849 - accuracy: 0.9258 - loss: 0.1666\n",
      "Layers: 3, Accuracy: 0.9332, AUC: 0.9825\n",
      "\n",
      "--- Résultats Finaux ---\n",
      "   Accuracy       AUC\n",
      "2  0.925855  0.975126\n",
      "3  0.933206  0.982493\n",
      "\n",
      "--- Détails pour 2 Couches de Convolution ---\n",
      "  Précision Moyenne: 0.9259\n",
      "  AUC Moyenne: 0.9751\n",
      "\n",
      "--- Détails pour 3 Couches de Convolution ---\n",
      "  Précision Moyenne: 0.9332\n",
      "  AUC Moyenne: 0.9825\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 170\u001b[0m\n\u001b[0;32m    167\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    169\u001b[0m display_results(results)\n\u001b[1;32m--> 170\u001b[0m plot_results([history \u001b[38;5;28;01mfor\u001b[39;00m _, history \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems()], conv_layers_list)\n",
      "Cell \u001b[1;32mIn[1], line 151\u001b[0m, in \u001b[0;36mplot_results\u001b[1;34m(histories, conv_layers_list)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_results\u001b[39m(histories, conv_layers_list):\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m num_layers, history \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(conv_layers_list, histories):\n\u001b[1;32m--> 151\u001b[0m         plt\u001b[38;5;241m.\u001b[39mplot(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    152\u001b[0m         plt\u001b[38;5;241m.\u001b[39mplot(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    153\u001b[0m         plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Convolutional Layers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "# Import des bibliothèques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Vérification de la disponibilité des GPUs\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Définition des hyperparamètres globaux\n",
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "FOLDS = 3\n",
    "DATA_DIR = '../../../chest_xray/train'\n",
    "\n",
    "# 1. Objectif et hypothèses\n",
    "# (écrivez vos objectifs et hypothèses dans une cellule de texte Markdown si vous utilisez Jupyter Notebook)\n",
    "\n",
    "# 2. Préparation des données\n",
    "def load_data(data_dir):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    "    )\n",
    "    \n",
    "    train_data = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    val_data = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        color_mode='grayscale',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "train_data, val_data = load_data(DATA_DIR)\n",
    "\n",
    "# 3. Définition du modèle CNN\n",
    "def create_model(num_conv_layers):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1)))  # Conversion en niveaux de gris\n",
    "    \n",
    "    for i in range(num_conv_layers):\n",
    "        model.add(layers.Conv2D(16 * (2**i), (3, 3), activation='relu')) \n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "    return model\n",
    "\n",
    "# 4. Entraînement du modèle avec validation croisée\n",
    "def k_fold_cross_validation(num_conv_layers, train_data, val_data):\n",
    "    kf = KFold(n_splits=FOLDS, shuffle=True)\n",
    "    accuracy_list, auc_list, all_histories = [], [], []\n",
    "\n",
    "    for train_index, val_index in kf.split(train_data):\n",
    "        model = create_model(num_conv_layers)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "        \n",
    "        history = model.fit(train_data, validation_data=val_data, epochs=EPOCHS, callbacks=[early_stopping], verbose=0)\n",
    "        all_histories.append(history.history)\n",
    "        \n",
    "        val_loss, val_accuracy, val_auc = model.evaluate(val_data)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        auc_list.append(val_auc)\n",
    "\n",
    "    return np.mean(accuracy_list), np.mean(auc_list), all_histories\n",
    "\n",
    "# Test avec différents nombres de couches de convolution\n",
    "conv_layers_list = [2, 3]\n",
    "results = {}\n",
    "\n",
    "for num_layers in conv_layers_list:\n",
    "    accuracy, roc_auc, histories = k_fold_cross_validation(num_layers, train_data, val_data)\n",
    "    results[num_layers] = {'Accuracy': accuracy, 'AUC': roc_auc}\n",
    "    print(f'Layers: {num_layers}, Accuracy: {accuracy:.4f}, AUC: {roc_auc:.4f}')\n",
    "\n",
    "# 5. Évaluation finale sur les données de test\n",
    "def evaluate_on_test_data(model, test_data):\n",
    "    val_loss, val_accuracy, val_auc = model.evaluate(test_data)\n",
    "    print(f\"\\nTest Loss: {val_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test AUC: {val_auc:.4f}\")\n",
    "\n",
    "# 6. Interprétation des prédictions avec Grad-CAM\n",
    "def grad_cam(model, img_array, last_conv_layer_name=\"conv2d\"):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    conv_outputs *= pooled_grads\n",
    "\n",
    "    heatmap = tf.reduce_mean(conv_outputs, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    heatmap = heatmap.numpy()\n",
    "    return heatmap\n",
    "\n",
    "# Fonction pour superposer la carte thermique sur l'image\n",
    "def superimpose_heatmap(img_path, heatmap):\n",
    "    img = cv2.imread(img_path)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "    return superimposed_img\n",
    "\n",
    "# 7. Conclusion\n",
    "def display_results(results):\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    print(\"\\n--- Résultats Finaux ---\")\n",
    "    print(results_df)\n",
    "    for num_layers, metrics in results.items():\n",
    "        print(f\"\\n--- Détails pour {num_layers} Couches de Convolution ---\")\n",
    "        print(f\"  Précision Moyenne: {metrics['Accuracy']:.4f}\")\n",
    "        print(f\"  AUC Moyenne: {metrics['AUC']:.4f}\")\n",
    "\n",
    "def plot_results(histories, conv_layers_list):\n",
    "    for num_layers, history in zip(conv_layers_list, histories):\n",
    "        plt.plot(history['accuracy'], label='Accuracy')\n",
    "        plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f'Model Accuracy for {num_layers} Convolutional Layers')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history['loss'], label='Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f'Model Loss for {num_layers} Convolutional Layers')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "display_results(results)\n",
    "plot_results([history for _, history in results.items()], conv_layers_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
