{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd43f8a7-da44-4f0f-bf25-29e8fa95befa",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print(\"imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c176e4d-d3a5-4e3e-bc39-aeda107a2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e70e842-2dc0-4343-970b-ba8df55895c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypermarameters loaded...\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "FOLDS = 5\n",
    "DATA_DIR = '../../../chest_xray/train'\n",
    "\n",
    "print(\"hypermarameters loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1baab580-9982-48b5-895c-a405605aec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    \n",
    "    train_data = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    val_data = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "train_data, val_data = load_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4cdf93-e4f4-4eb9-a986-61badddd67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2: Création du modèle\n",
    "def create_model(num_conv_layers):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    print(\"Création de la couche d'entrée...\")\n",
    "    model.add(layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)))  # Modifié ici\n",
    "\n",
    "    print(f\"Ajout de {num_conv_layers} couches de convolution...\")\n",
    "    for i in range(num_conv_layers):\n",
    "        print(f\"Ajout de la couche de convolution {i+1}...\")\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    print(\"Ajout de la couche Flatten...\")\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    print(\"Ajout de la couche Dense avec 128 unités...\")\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "    print(\"Ajout de la couche de sortie avec activation sigmoid...\")\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(\"Compilation du modèle...\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"Modèle créé avec succès.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c3286e-f07f-438d-96d2-046029c94777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 3: Validation croisée K-Fold\n",
    "def k_fold_cross_validation(num_conv_layers, train_data, val_data):\n",
    "    kf = KFold(n_splits=FOLDS, shuffle=True)\n",
    "    accuracy_list = []\n",
    "    auc_list = []\n",
    "    all_histories = []  # Pour stocker les historiques d'entraînement\n",
    "\n",
    "    print(f\"Début de la validation croisée K-Fold avec {FOLDS} plis...\")\n",
    "\n",
    "    # Boucle à travers les différentes plis\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_data)):\n",
    "        print(f\"Plis {fold+1}/{FOLDS}\")\n",
    "\n",
    "        # Créer un modèle\n",
    "        print(\"Création du modèle...\")\n",
    "        model = create_model(num_conv_layers)\n",
    "\n",
    "        # Entraînement avec EarlyStopping pour éviter le sur-apprentissage\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        print(\"Début de l'entraînement...\")\n",
    "        history = model.fit(train_data, validation_data=val_data, epochs=EPOCHS, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # Stocker l'historique\n",
    "        all_histories.append(history.history)\n",
    "\n",
    "        # Évaluation\n",
    "        print(\"Évaluation du modèle...\")\n",
    "        val_loss, val_accuracy = model.evaluate(val_data, verbose=0)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "\n",
    "        # Calcul de la courbe ROC\n",
    "        y_true = val_data.classes\n",
    "        y_scores = model.predict(val_data).ravel()\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_list.append(roc_auc)\n",
    "\n",
    "        print(f\"Plis {fold+1} terminé. Accuracy: {val_accuracy}, AUC: {roc_auc}\\n\")\n",
    "\n",
    "    print(\"Validation croisée terminée.\")\n",
    "    mean_accuracy = np.mean(accuracy_list)\n",
    "    mean_auc = np.mean(auc_list)\n",
    "    print(f\"Accuracy moyenne: {mean_accuracy}\")\n",
    "    print(f\"AUC moyenne: {mean_auc}\")\n",
    "\n",
    "    return mean_accuracy, mean_auc, all_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23778c7-0d70-4def-822d-ab6a3b56e27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikne\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    }
   ],
   "source": [
    "# Étape 4: Test avec différents nombres de couches de convolution\n",
    "conv_layers_list = [2, 3, 4, 5]  # Tester avec 2 à 5 couches\n",
    "results = {}\n",
    "\n",
    "for num_layers in conv_layers_list:\n",
    "    accuracy, roc_auc, histories = k_fold_cross_validation(num_layers)\n",
    "    results[num_layers] = {'Accuracy': accuracy, 'AUC': roc_auc}\n",
    "    print(f'Layers: {num_layers}, Accuracy: {accuracy:.4f}, AUC: {roc_auc:.4f}')\n",
    "\n",
    "    # Visualisation des courbes d'entraînement\n",
    "    for history in histories:\n",
    "        plt.plot(history['accuracy'], label='Accuracy')\n",
    "        plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f'Model Accuracy for {num_layers} Convolutional Layers')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history['loss'], label='Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f'Model Loss for {num_layers} Convolutional Layers')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dfb23a-29bf-4b98-b8f4-2d19262624b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "results_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Impact of Number of Convolutional Layers on Model Performance')\n",
    "plt.xlabel('Number of Convolutional Layers')\n",
    "plt.ylabel('Performance Metrics')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f05ce1-a0e6-4dcf-99ed-ace15924d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(histories):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Précision\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history in histories:\n",
    "        plt.plot(history['accuracy'], label='Train')\n",
    "        plt.plot(history['val_accuracy'], label='Validation', linestyle='--')\n",
    "    plt.title('Learning Curves - Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Perte\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history in histories:\n",
    "        plt.plot(history['loss'], label='Train')\n",
    "        plt.plot(history['val_loss'], label='Validation', linestyle='--')\n",
    "    plt.title('Learning Curves - Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7c29a-0171-41c4-b41c-9fef88dd16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(num_layers, histories):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for history in histories:\n",
    "        y_true = val_data.classes\n",
    "        y_scores = model.predict(val_data).ravel()\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "        plt.plot(fpr, tpr, lw=1, label=f'ROC curve for {num_layers} layers (AUC = {auc(fpr, tpr):.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67569f8e-5387-4d44-8dd3-f6c524dae8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_layers in conv_layers_list:\n",
    "    plot_learning_curves(results[num_layers]['Histories'])\n",
    "    plot_roc_curves(num_layers, results[num_layers]['Histories'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
